import streamlit as st
import asyncio
import os
import numpy as np
import faiss
import requests
from sentence_transformers import SentenceTransformer
from PIL import Image
import pytesseract
import fitz  # PyMuPDF
import whisper

from moviepy import VideoFileClip

# ä¿®å¾© Streamlit + asyncio éŒ¯èª¤
try:
    asyncio.get_running_loop()
except RuntimeError:
    asyncio.set_event_loop(asyncio.new_event_loop())

# åˆå§‹åŒ–å‘é‡æ¨¡å‹èˆ‡ç´¢å¼•
embed_model = SentenceTransformer('all-MiniLM-L6-v2')
dimension = 384
index = faiss.IndexFlatL2(dimension)
documents = []
vectors = []

# è™•ç†ä¸åŒæ ¼å¼çš„æ–‡ä»¶
def extract_text(file):
    if file.type == "text/plain":
        return file.read().decode("utf-8")

    elif file.type == "application/pdf":
        pdf_doc = fitz.open(stream=file.read(), filetype="pdf")
        return "\n".join(page.get_text() for page in pdf_doc)

    elif file.type.startswith("image/"):
        image = Image.open(file)
        return pytesseract.image_to_string(image, lang="eng")  # è‹¥éœ€ä¸­æ–‡ç”¨ "chi_tra"

    elif file.type.startswith("video/"):
        temp_path = "temp_video.mp4"
        with open(temp_path, "wb") as f:
            f.write(file.read())
        video = VideoFileClip(temp_path)
        audio_path = "temp_audio.wav"
        video.audio.write_audiofile(audio_path)
        model = whisper.load_model("base")
        result = model.transcribe(audio_path)
        os.remove(temp_path)
        os.remove(audio_path)
        return result["text"]

    else:
        return ""

# UIï¼šä¸»é 
st.set_page_config(page_title="RAG æ–‡ä»¶å•ç­”ç³»çµ±", layout="centered")
st.title("ğŸ“‚ æ–‡ä»¶æª¢ç´¢å•ç­”ç³»çµ±ï¼ˆRAG + Ollamaï¼‰")
st.caption("æ”¯æ´ `.txt`ã€`.pdf`ã€åœ–ç‰‡ï¼ˆ.jpg/.pngï¼‰ã€å½±ç‰‡ï¼ˆ.mp4ï¼‰")

# ä¸Šå‚³æ–‡ä»¶
uploaded_files = st.file_uploader(
    "è«‹ä¸Šå‚³æ–‡ä»¶ï¼š",
    accept_multiple_files=True,
    type=["txt", "pdf", "jpg", "jpeg", "png", "mp4"]
)

# è™•ç†ä¸¦å»ºç«‹çŸ¥è­˜åº«å‘é‡
for file in uploaded_files:
    try:
        content = extract_text(file)
        if content:
            docs = content.split("\n\n")
            documents.extend(docs)
            vecs = embed_model.encode(docs)
            vectors.extend(vecs)
            st.success(f"âœ… æˆåŠŸè™•ç†ï¼š{file.name}")
        else:
            st.warning(f"âš ï¸ ç„¡æ³•è™•ç†å…§å®¹ï¼š{file.name}")
    except Exception as e:
        st.error(f"âŒ éŒ¯èª¤æ–¼ {file.name}ï¼š{e}")

# å°‡å‘é‡åŠ é€² FAISS index
if vectors:
    index.add(np.array(vectors))

# å•ç­”æ¬„ä½
question = st.text_input(" è«‹è¼¸å…¥ä½ çš„å•é¡Œ")
if st.button("é€å‡ºå•é¡Œ") and question and documents:
    q_vector = embed_model.encode([question])
    D, I = index.search(q_vector, k=3)
    retrieved_docs = "\n".join([documents[i] for i in I[0]])

    # æ„é€  prompt ä¸¦å‘¼å« Ollamaï¼ˆæœ¬åœ°æ¨¡å‹ï¼‰
    prompt = f"ä»¥ä¸‹æ˜¯æ–‡ä»¶å…§å®¹æ‘˜è¦ï¼š\n{retrieved_docs}\n\næ ¹æ“šé€™äº›å…§å®¹ï¼Œå›ç­”å•é¡Œï¼š{question}"
    try:
        response = requests.post("http://localhost:11434/api/generate", json={
            "model": "mistral",
            "prompt": prompt,
            "stream": False
        })
        answer = response.json().get("response", "âš ï¸ æ²’æœ‰å›å‚³æœ‰æ•ˆçµæœ")
        st.markdown("###  å›ç­”ï¼š")
        st.write(answer)
    except Exception as e:
        st.error(f"âŒ ç„¡æ³•é€£ç·šåˆ°æœ¬åœ°æ¨¡å‹ï¼ˆOllamaï¼‰: {e}")